{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81bf9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f26d26cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English locations: 357 entries\n",
      "Arabic locations: 357 entries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['iq', 'jo', 'lb', 'ps', 'sy', 'iq_an', 'iq_ar', 'iq_bb', 'iq_bg', 'iq_ba', 'iq_da', 'iq_dq', 'iq_qa', 'iq_di', 'iq_ka', 'iq_ts', 'iq_ma', 'iq_mu', 'iq_na', 'iq_ni', 'iq_sd', 'iq_sl', 'iq_wa', 'jo_aj', 'jo_am', 'jo_aq', 'jo_ba', 'jo_ir', 'jo_ja', 'jo_ka', 'jo_mn', 'jo_md', 'jo_ma', 'jo_at', 'jo_az', 'lb_ak', 'lb_bh', 'lb_ba', 'lb_bq', 'lb_00_0', 'lb_jl', 'lb_na', 'lb_nl', 'lb_ja', 'ps_gz', 'ps_wb', 'sy_hl', 'sy_di', 'sy_dr', 'sy_dy', 'sy_hm', 'sy_ha', 'sy_hi', 'sy_id', 'sy_la', 'sy_qu', 'sy_ra', 'sy_rd', 'sy_su', 'sy_ta', 'iq_ba_1', 'iq_bg_1', 'iq_sd_1', 'iq_bg_2', 'iq_qa_1', 'iq_ka_1', 'iq_ni_1', 'iq_ma_4', 'iq_da_1', 'iq_ma_5', 'iq_an_3', 'iq_ni_4', 'iq_00_0', 'iq_wa_1', 'iq_ni_2', 'iq_di_3', 'iq_wa_5', 'iq_00_1', 'iq_sd_5', 'iq_ni_3', 'iq_sd_6', 'iq_di_4', 'iq_ba_5', 'iq_00_2', 'iq_sl_1', 'iq_dq_1', 'iq_ar_1', 'iq_ts_2', 'iq_da_2', 'iq_ts_3', 'iq_sl_2', 'iq_qa_3', 'iq_sl_3', 'iq_sd_2', 'iq_ar_2', 'iq_an_4', 'iq_ba_6', 'iq_an_5', 'iq_wa_2', 'iq_sl_4', 'iq_qa_4', 'iq_bb_3', 'iq_ni_5', 'iq_ts_1', 'iq_an_6', 'iq_bb_4', 'iq_ka_2', 'iq_00_3', 'iq_an_1', 'iq_bg_4', 'iq_ma_1', 'iq_sl_5', 'iq_bg_5', 'iq_00_4', 'iq_ka_3', 'iq_di_1', 'iq_di_5', 'iq_mu_1', 'iq_00_5', 'iq_di_6', 'iq_ts_4', 'iq_ar_3', 'iq_na_2', 'iq_wa_6', 'iq_bg_6', 'iq_bb_1', 'iq_bg_7', 'iq_ma_2', 'iq_ar_4', 'iq_na_1', 'iq_00_6', 'iq_00_7', 'iq_ma_3', 'iq_ar_5', 'iq_ba_2', 'iq_di_2', 'iq_ni_6', 'iq_bb_2', 'iq_wa_3', 'iq_na_3', 'iq_00_8', 'iq_dq_4', 'iq_sl_6', 'iq_sl_7', 'iq_ma_6', 'iq_00_9', 'iq_ba_3', 'iq_an_7', 'iq_bg_9', 'iq_an_8', 'iq_sl_8', 'iq_bg_3', 'iq_00_10', 'iq_dq_2', 'iq_mu_2', 'iq_an_2', 'iq_00_11', 'iq_mu_3', 'iq_sd_7', 'iq_mu_4', 'iq_qa_2', 'iq_ar_6', 'iq_00_12', 'iq_sl_9', 'iq_dq_3', 'iq_ba_7', 'iq_ni_7', 'iq_sd_3', 'iq_00_13', 'iq_00_14', 'iq_ar_7', 'iq_sl_10', 'iq_da_3', 'iq_dq_5', 'iq_wa_4', 'iq_00_15', 'iq_ni_9', 'iq_bg_8', 'iq_ni_8', 'iq_bg_10', 'iq_sd_4', 'iq_sd_8', 'iq_sd_9', 'iq_00_16', 'iq_da_4', 'iq_ba_4', 'jo_ka_5', 'jo_ka_1', 'jo_ir_1', 'jo_mn_1', 'jo_aj_1', 'jo_am_3', 'jo_aq_2', 'jo_ba_1', 'jo_ba_4', 'jo_md_2', 'jo_00_0', 'jo_00_1', 'jo_ma_2', 'jo_ir_7', 'jo_ir_8', 'jo_00_2', 'jo_at_2', 'jo_ba_5', 'jo_00_3', 'jo_az_1', 'jo_ka_6', 'jo_ba_7', 'jo_at_1', 'jo_az_2', 'jo_ba_6', 'jo_ir_9', 'jo_mn_2', 'jo_am_4', 'jo_ja_1', 'jo_am_1', 'jo_ka_7', 'jo_ir_2', 'jo_aj_2', 'jo_mn_5', 'jo_md_1', 'jo_ma_3', 'jo_am_5', 'jo_ka_2', 'jo_ir_3', 'jo_mn_3', 'jo_am_2', 'jo_am_6', 'jo_ka_3', 'jo_ka_4', 'jo_at_3', 'jo_am_7', 'jo_aq_1', 'jo_ir_4', 'jo_ba_2', 'jo_ma_1', 'jo_ma_4', 'jo_am_8', 'jo_ba_3', 'jo_ma_5', 'jo_mn_4', 'jo_ir_5', 'jo_am_9', 'jo_aq_3', 'jo_mn_6', 'jo_ir_6', 'jo_az_3', 'jo_ba_8', 'jo_00_4', 'lb_ak_1', 'lb_jl_1', 'lb_jl_2', 'lb_bh_1', 'lb_nl_1', 'lb_nl_2', 'lb_ba_1', 'lb_na_1', 'lb_jl_5', 'lb_jl_3', 'lb_na_2', 'lb_bh_2', 'lb_ja_1', 'lb_jl_6', 'lb_nl_3', 'lb_na_3', 'lb_jl_4', 'lb_nl_4', 'lb_na_4', 'lb_bq_1', 'lb_ja_2', 'lb_ja_3', 'lb_nl_5', 'lb_bq_2', 'lb_bq_3', 'lb_nl_6', 'ps_wb_3', 'ps_wb_4', 'ps_gz_1', 'ps_gz_2', 'ps_wb_1', 'ps_gz_3', 'ps_wb_5', 'ps_wb_2', 'ps_gz_4', 'ps_wb_6', 'ps_wb_7', 'ps_gz_5', 'ps_wb_8', 'ps_wb_9', 'ps_wb_10', 'ps_wb_11', 'sy_hl_5', 'sy_hl_1', 'sy_dy_1', 'sy_hl_2', 'sy_ha_3', 'sy_la_3', 'sy_qu_2', 'sy_ra_2', 'sy_id_1', 'sy_su_1', 'sy_ta_1', 'sy_rd_3', 'sy_00_0', 'sy_hl_3', 'sy_ta_2', 'sy_di_1', 'sy_rd_7', 'sy_dr_3', 'sy_rd_5', 'sy_dy_2', 'sy_00_1', 'sy_rd_6', 'sy_ta_3', 'sy_ha_1', 'sy_qu_1', 'sy_la_1', 'sy_hm_2', 'sy_id_2', 'sy_hi_4', 'sy_id_5', 'sy_dr_2', 'sy_hl_6', 'sy_la_2', 'sy_hl_7', 'sy_id_3', 'sy_id_4', 'sy_hm_4', 'sy_hi_1', 'sy_hl_8', 'sy_hm_3', 'sy_dy_3', 'sy_00_2', 'sy_rd_2', 'sy_ha_2', 'sy_la_4', 'sy_rd_8', 'sy_00_3', 'sy_hi_2', 'sy_rd_1', 'sy_ha_4', 'sy_hi_3', 'sy_hl_4', 'sy_ta_5', 'sy_hm_5', 'sy_su_2', 'sy_dr_1', 'sy_hm_1', 'sy_su_3', 'sy_hi_5', 'sy_00_4', 'sy_hi_6', 'sy_ra_3', 'sy_ta_4', 'sy_ra_1', 'sy_rd_9', 'sy_rd_4'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pickle files and understand their structure\n",
    "with open('data/id_english_location_name.pkl', 'rb') as f:\n",
    "    english_locations = pickle.load(f)\n",
    "\n",
    "with open('data/id_arabic_location_name.pkl', 'rb') as f:\n",
    "    arabic_locations = pickle.load(f)\n",
    "\n",
    "print(f\"English locations: {len(english_locations)} entries\")\n",
    "print(f\"Arabic locations: {len(arabic_locations)} entries\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "252dfc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level distribution:\n",
      "level\n",
      "district    298\n",
      "province     54\n",
      "country       5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Country codes: ['iq' 'jo' 'lb' 'ps' 'sy']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_id</th>\n",
       "      <th>level</th>\n",
       "      <th>country_code</th>\n",
       "      <th>province_code</th>\n",
       "      <th>district_number</th>\n",
       "      <th>names</th>\n",
       "      <th>primary_name</th>\n",
       "      <th>name_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iq</td>\n",
       "      <td>country</td>\n",
       "      <td>iq</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[iraq]</td>\n",
       "      <td>iraq</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jo</td>\n",
       "      <td>country</td>\n",
       "      <td>jo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[jordan]</td>\n",
       "      <td>jordan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lb</td>\n",
       "      <td>country</td>\n",
       "      <td>lb</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[lebanon]</td>\n",
       "      <td>lebanon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ps</td>\n",
       "      <td>country</td>\n",
       "      <td>ps</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[occupied palestinian territory, palestine, pa...</td>\n",
       "      <td>occupied palestinian territory</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sy</td>\n",
       "      <td>country</td>\n",
       "      <td>sy</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[syria, syrian arab republic]</td>\n",
       "      <td>syria</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iq_an</td>\n",
       "      <td>province</td>\n",
       "      <td>iq</td>\n",
       "      <td>an</td>\n",
       "      <td>None</td>\n",
       "      <td>[anbar]</td>\n",
       "      <td>anbar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>iq_ar</td>\n",
       "      <td>province</td>\n",
       "      <td>iq</td>\n",
       "      <td>ar</td>\n",
       "      <td>None</td>\n",
       "      <td>[arbil, erbil]</td>\n",
       "      <td>arbil</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>iq_bb</td>\n",
       "      <td>province</td>\n",
       "      <td>iq</td>\n",
       "      <td>bb</td>\n",
       "      <td>None</td>\n",
       "      <td>[babil, babylon]</td>\n",
       "      <td>babil</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iq_bg</td>\n",
       "      <td>province</td>\n",
       "      <td>iq</td>\n",
       "      <td>bg</td>\n",
       "      <td>None</td>\n",
       "      <td>[baghdad]</td>\n",
       "      <td>baghdad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iq_ba</td>\n",
       "      <td>province</td>\n",
       "      <td>iq</td>\n",
       "      <td>ba</td>\n",
       "      <td>None</td>\n",
       "      <td>[basra, basrah]</td>\n",
       "      <td>basra</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  location_id     level country_code province_code district_number  \\\n",
       "0          iq   country           iq          None            None   \n",
       "1          jo   country           jo          None            None   \n",
       "2          lb   country           lb          None            None   \n",
       "3          ps   country           ps          None            None   \n",
       "4          sy   country           sy          None            None   \n",
       "5       iq_an  province           iq            an            None   \n",
       "6       iq_ar  province           iq            ar            None   \n",
       "7       iq_bb  province           iq            bb            None   \n",
       "8       iq_bg  province           iq            bg            None   \n",
       "9       iq_ba  province           iq            ba            None   \n",
       "\n",
       "                                               names  \\\n",
       "0                                             [iraq]   \n",
       "1                                           [jordan]   \n",
       "2                                          [lebanon]   \n",
       "3  [occupied palestinian territory, palestine, pa...   \n",
       "4                      [syria, syrian arab republic]   \n",
       "5                                            [anbar]   \n",
       "6                                     [arbil, erbil]   \n",
       "7                                   [babil, babylon]   \n",
       "8                                          [baghdad]   \n",
       "9                                    [basra, basrah]   \n",
       "\n",
       "                     primary_name  name_count  \n",
       "0                            iraq           1  \n",
       "1                          jordan           1  \n",
       "2                         lebanon           1  \n",
       "3  occupied palestinian territory           4  \n",
       "4                           syria           2  \n",
       "5                           anbar           1  \n",
       "6                           arbil           2  \n",
       "7                           babil           2  \n",
       "8                         baghdad           1  \n",
       "9                           basra           2  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create separate English and Arabic DataFrames with hierarchical structure for inspection\n",
    "# perhaps it is still easier to match with dicts later for analysis but I am better with understanding dataframes\n",
    "def parse_location_hierarchy(location_id):\n",
    "    \"\"\"Parse the hierarchical structure from location_id\"\"\"\n",
    "    parts = location_id.split('_')\n",
    "    \n",
    "    if len(parts) == 1:\n",
    "        return {\n",
    "            'level': 'country',\n",
    "            'country_code': parts[0],\n",
    "            'province_code': None,\n",
    "            'district_number': None\n",
    "        }\n",
    "    elif len(parts) == 2:\n",
    "        return {\n",
    "            'level': 'province', \n",
    "            'country_code': parts[0],\n",
    "            'province_code': parts[1],\n",
    "            'district_number': None\n",
    "        }\n",
    "    elif len(parts) == 3:\n",
    "        return {\n",
    "            'level': 'district',\n",
    "            'country_code': parts[0], \n",
    "            'province_code': parts[1],\n",
    "            'district_number': parts[2]\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'level': 'unknown',\n",
    "            'country_code': None,\n",
    "            'province_code': None, \n",
    "            'district_number': None\n",
    "        }\n",
    "\n",
    "# Create English DataFrame\n",
    "english_data = []\n",
    "for location_id, names in english_locations.items():\n",
    "    hierarchy = parse_location_hierarchy(location_id)\n",
    "    \n",
    "    # Handle both single strings and lists\n",
    "    if isinstance(names, str):\n",
    "        names = [names]\n",
    "    elif hasattr(names, 'tolist'):  # numpy array\n",
    "        names = names.tolist()\n",
    "    \n",
    "    english_data.append({\n",
    "        'location_id': location_id,\n",
    "        'level': hierarchy['level'],\n",
    "        'country_code': hierarchy['country_code'],\n",
    "        'province_code': hierarchy['province_code'],\n",
    "        'district_number': hierarchy['district_number'],\n",
    "        'names': names,\n",
    "        'primary_name': names[0] if names else None,\n",
    "        'name_count': len(names)\n",
    "    })\n",
    "\n",
    "english_df = pd.DataFrame(english_data)\n",
    "\n",
    "# Show the hierarchy\n",
    "print(f\"\\nLevel distribution:\")\n",
    "print(english_df['level'].value_counts())\n",
    "\n",
    "print(f\"\\nCountry codes: {english_df['country_code'].unique()}\")\n",
    "english_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c5936b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabic DataFrame: (357, 8)\n",
      "Columns: ['location_id', 'level', 'country_code', 'province_code', 'district_number', 'names', 'primary_name', 'name_count']\n"
     ]
    }
   ],
   "source": [
    "# Create Arabic DataFrame with same structure\n",
    "arabic_data = []\n",
    "for location_id, names in arabic_locations.items():\n",
    "    hierarchy = parse_location_hierarchy(location_id)\n",
    "    \n",
    "    # Handle both single strings and lists\n",
    "    if isinstance(names, str):\n",
    "        names = [names]\n",
    "    elif hasattr(names, 'tolist'):  # numpy array\n",
    "        names = names.tolist()\n",
    "    \n",
    "    arabic_data.append({\n",
    "        'location_id': location_id,\n",
    "        'level': hierarchy['level'],\n",
    "        'country_code': hierarchy['country_code'],\n",
    "        'province_code': hierarchy['province_code'],\n",
    "        'district_number': hierarchy['district_number'],\n",
    "        'names': names,\n",
    "        'primary_name': names[0] if names else None,\n",
    "        'name_count': len(names)\n",
    "    })\n",
    "\n",
    "arabic_df = pd.DataFrame(arabic_data)\n",
    "\n",
    "print(f\"Arabic DataFrame: {arabic_df.shape}\")\n",
    "print(f\"Columns: {list(english_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcf596e",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "As it is hierarchical I'd assume that if we match on district level we can automatically assign back to province and country as well. So perhaps we should \"tag\" the news articles with country, province and district code/number - based on occurences of names and primary names in the article. \n",
    "\n",
    "Multiple matches/tags are of course possible so need to be careful on how to do that. We could work with binary tags, but then would append 300+ columns which seems super inefficient and will lead to sparse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaf415d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b6ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# LOCATION MATCHING AND PRIMARY LOCATION SCRIPTS FOR NEWS ANALYSIS\n",
    "# (To be used later when processing news articles)\n",
    "# ======================================================================\n",
    "\n",
    "def create_location_lookup(df):\n",
    "    \"\"\"Create a lookup dictionary for matching location names in text\"\"\"\n",
    "    lookup = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        location_info = {\n",
    "            'location_id': row['location_id'],\n",
    "            'level': row['level'],\n",
    "            'country_code': row['country_code'],\n",
    "            'province_code': row['province_code'],\n",
    "            'district_number': row['district_number']\n",
    "        }\n",
    "        \n",
    "        # Add all name variations to lookup\n",
    "        for name in row['names']:\n",
    "            name_clean = name.lower().strip()\n",
    "            if name_clean not in lookup:\n",
    "                lookup[name_clean] = []\n",
    "            lookup[name_clean].append(location_info)\n",
    "    \n",
    "    return lookup\n",
    "\n",
    "def determine_primary_location(title, body, location_matches):\n",
    "    \"\"\"\n",
    "    Determine primary location from multiple location mentions using scoring algorithm\n",
    "    \n",
    "    Args:\n",
    "        title: Article title text\n",
    "        body: Article body text  \n",
    "        location_matches: List of matched location dictionaries\n",
    "    \n",
    "    Returns:\n",
    "        dict: Primary location info + secondary locations list\n",
    "    \"\"\"\n",
    "    \n",
    "    if not location_matches:\n",
    "        return {'primary': None, 'secondary': [], 'method': 'no_matches'}\n",
    "    \n",
    "    if len(location_matches) == 1:\n",
    "        return {'primary': location_matches[0], 'secondary': [], 'method': 'single_match'}\n",
    "    \n",
    "    # Score each location\n",
    "    for location in location_matches:\n",
    "        score = 0\n",
    "        location_name = location.get('matched_name', '').lower()\n",
    "        \n",
    "        # Specificity bonus (district=3, province=2, country=1)\n",
    "        level_scores = {'district': 3, 'province': 2, 'country': 1}\n",
    "        score += level_scores.get(location['level'], 0)\n",
    "        \n",
    "        # Title mention bonus\n",
    "        if location_name in title.lower():\n",
    "            score += 5\n",
    "            \n",
    "        # Frequency bonus (count mentions in title + body)\n",
    "        full_text = (title + ' ' + body).lower()\n",
    "        mention_count = full_text.count(location_name)\n",
    "        score += mention_count * 0.5\n",
    "        \n",
    "        # Context bonus (simple check for action words)\n",
    "        action_patterns = [f'in {location_name}', f'{location_name} faces', f'{location_name} experiences']\n",
    "        for pattern in action_patterns:\n",
    "            if pattern in full_text:\n",
    "                score += 3\n",
    "                break\n",
    "                \n",
    "        # Emphasis bonus (affected, hit, impacted)\n",
    "        emphasis_patterns = [f'{location_name} most', f'{location_name} severely', f'{location_name} heavily']\n",
    "        for pattern in emphasis_patterns:\n",
    "            if pattern in full_text:\n",
    "                score += 2\n",
    "                break\n",
    "                \n",
    "        location['primary_score'] = score\n",
    "    \n",
    "    # Sort by score and select primary\n",
    "    location_matches.sort(key=lambda x: x['primary_score'], reverse=True)\n",
    "    primary = location_matches[0]\n",
    "    secondary = location_matches[1:]\n",
    "    \n",
    "    return {\n",
    "        'primary': primary,\n",
    "        'secondary': secondary,\n",
    "        'method': 'scored',\n",
    "        'primary_score': primary['primary_score']\n",
    "    }\n",
    "\n",
    "def tag_article_with_geography(title, body, english_lookup, arabic_lookup):\n",
    "    \"\"\"\n",
    "    Complete function to tag an article with geographic information\n",
    "    \n",
    "    Args:\n",
    "        title: Article title\n",
    "        body: Article body text\n",
    "        english_lookup: English location name lookup dictionary\n",
    "        arabic_lookup: Arabic location name lookup dictionary\n",
    "    \n",
    "    Returns:\n",
    "        dict: Geographic tags for the article\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all location matches\n",
    "    all_matches = []\n",
    "    text_combined = (title + ' ' + body).lower()\n",
    "    \n",
    "    # Check English locations\n",
    "    for name, location_infos in english_lookup.items():\n",
    "        if name in text_combined:\n",
    "            for location_info in location_infos:\n",
    "                location_info = location_info.copy()\n",
    "                location_info['matched_name'] = name\n",
    "                location_info['language'] = 'english'\n",
    "                all_matches.append(location_info)\n",
    "    \n",
    "    # Check Arabic locations  \n",
    "    for name, location_infos in arabic_lookup.items():\n",
    "        if name in text_combined:\n",
    "            for location_info in location_infos:\n",
    "                location_info = location_info.copy()\n",
    "                location_info['matched_name'] = name\n",
    "                location_info['language'] = 'arabic'\n",
    "                all_matches.append(location_info)\n",
    "    \n",
    "    # Remove duplicates (same location_id)\n",
    "    unique_matches = []\n",
    "    seen_ids = set()\n",
    "    for match in all_matches:\n",
    "        if match['location_id'] not in seen_ids:\n",
    "            unique_matches.append(match)\n",
    "            seen_ids.add(match['location_id'])\n",
    "    \n",
    "    # Determine primary location\n",
    "    result = determine_primary_location(title, body, unique_matches)\n",
    "    \n",
    "    # Format final result\n",
    "    if result['primary']:\n",
    "        primary = result['primary']\n",
    "        geographic_tags = {\n",
    "            'primary_country': primary['country_code'],\n",
    "            'primary_province': primary['province_code'],\n",
    "            'primary_district': primary['district_number'],\n",
    "            'primary_level': primary['level'],\n",
    "            'primary_location_id': primary['location_id'],\n",
    "            'secondary_locations': [loc['location_id'] for loc in result['secondary']],\n",
    "            'total_locations_found': len(unique_matches),\n",
    "            'geographic_scope': 'multi_location' if len(unique_matches) > 1 else 'single_location',\n",
    "            'cross_border': len(set(match['country_code'] for match in unique_matches)) > 1,\n",
    "            'tagging_confidence': result.get('primary_score', 0),\n",
    "            'tagging_method': result['method']\n",
    "        }\n",
    "    else:\n",
    "        geographic_tags = {\n",
    "            'primary_country': None,\n",
    "            'primary_province': None,\n",
    "            'primary_district': None,\n",
    "            'primary_level': None,\n",
    "            'primary_location_id': None,\n",
    "            'secondary_locations': [],\n",
    "            'total_locations_found': 0,\n",
    "            'geographic_scope': 'no_location',\n",
    "            'cross_border': False,\n",
    "            'tagging_confidence': 0,\n",
    "            'tagging_method': 'no_matches'\n",
    "        }\n",
    "    \n",
    "    return geographic_tags\n",
    "\n",
    "print(\"Geographic tagging functions defined:\")\n",
    "print(\"- create_location_lookup(): Create name->location lookup dictionary\")\n",
    "print(\"- determine_primary_location(): Score and select primary location from matches\")\n",
    "print(\"- tag_article_with_geography(): Complete article tagging pipeline\")\n",
    "print(\"\\nThese will be used when processing news articles.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb-ta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
